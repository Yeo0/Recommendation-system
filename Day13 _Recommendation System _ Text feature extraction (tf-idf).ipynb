{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning :: Text feature extraction (tf-idf) – Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = (\"The sky is blue.\", \"The sun is bright.\")\n",
    "test_set = (\"The sun in the sky is bright.\", \"We can see the shining sun, the bright sun.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### countervectorizer\n",
    "- 문서를 토큰 리스트로 변환한다.\n",
    "- 각 문서에서 토큰의 출현 빈도를 센다.\n",
    "- 각 문서를 BOW 인코딩 벡터로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer() #convert the text to lowercase, accents removal, token extraction, filter stop words, etc…\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 5, 'sky': 3, 'is': 2, 'blue': 0, 'sun': 4, 'bright': 1}\n"
     ]
    }
   ],
   "source": [
    "vectorizer.fit_transform(train_set)\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t2\n",
      "  (1, 1)\t1\n",
      "  (1, 4)\t2\n",
      "  (1, 5)\t2\n"
     ]
    }
   ],
   "source": [
    "smatrix = vectorizer.transform(test_set)\n",
    "print(smatrix) # vocabulary 에 있는 인덱스들이 얼만 큼 나왔는지 빈도 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 1, 1, 1, 1, 2],\n",
       "        [0, 1, 0, 0, 2, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smatrix.todense() #2*6 (2: cardinality / 6: feature 개수)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning :: Text feature extraction (tf-idf) – Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = (\"The sky is blue.\", \"The sun is bright.\")\n",
    "test_set = (\"The sun in the sky is bright.\", \"We can see the shining sun, the bright sun.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 5, 'sky': 3, 'is': 2, 'blue': 0, 'sun': 4, 'bright': 1}\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit_transform(train_set)\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_term_matrix = count_vectorizer.transform(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 1 1 2]\n",
      " [0 1 0 0 2 2]]\n"
     ]
    }
   ],
   "source": [
    "print(freq_term_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.09861229 1.         1.40546511 1.40546511 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer(norm=\"l2\")\n",
    "tfidf.fit(freq_term_matrix)\n",
    "print(tfidf.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.31701073 0.44554752 0.44554752 0.31701073 0.63402146]\n",
      " [0.         0.33333333 0.         0.         0.66666667 0.66666667]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_matrix = tfidf.transform(freq_term_matrix)\n",
    "print(tf_idf_matrix.todense())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
